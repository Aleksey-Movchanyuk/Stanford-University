pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week 4/machine-learning-ex4/ex4-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week 4/machine-learning-ex4/ex4-R")
}
## Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all
#  Instructions
#  ------------
#
#  This file contains code that helps you get started on the
#  linear exercise. You will need to complete the following functions
#  in this exericse:
#
#     lrCostFunction.R (logistic regression cost function)
#     oneVsAll.R
#     predictOneVsAll.R
#     predict.R
#
#  For this exercise, you will not need to change any code in this file,
#  or any other files other than those mentioned above.
#
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week 4/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week 4/machine-learning-ex3/ex3-R")
}
## Setup the parameters you will use for this part of the exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- nrow(X);
# Randomly select 100 data points to display
sel <- sample(nrow(X));
sel <- sel[1:100];
source("displayData.R")
displayData(X[sel,]);
print('Program paused. Press enter to continue.\n');
View(y)
sel <- sample(m);
sel <- sel[1:100];
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
# Create a shareable link to your chart
# Set up API credentials: https://plot.ly/r/getting-started
chart_link = plotly_POST(p, filename="scatter3d/basic")
chart_link
install.packages("plotly")
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
# Create a shareable link to your chart
# Set up API credentials: https://plot.ly/r/getting-started
chart_link = plotly_POST(p, filename="scatter3d/basic")
chart_link
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
library(кпд)
library(rgl)
install.packages("rgl")
install.packages("rgl")
install.packages("rgl")
install.packages("rgl")
install.packages("rgl")
install.packages("rgl")
package(rgl)
library(rgl)
uninstall.packages("jsonlite")
remove.packages("jsonlite")
install.packages("jsonlite", repos="http://cran.r-project.org")
install.packages("jsonlite", repos = "http://cran.r-project.org")
library(rgl)
install.packages("rgl", repos = "http://cran.r-project.org")
library(rgl)
library(rgl)
version()
R.Version()
library(rgl)
plot3d(iris[,1:3])
x = matrix(c(1,2,3,5), ncol=1)
x = matrix(c(1,2,3,5), nrow=4)
View(x)
theta = matrix(c(10,1,3,4))
View(theta)
theta = matrix(c(10,1,3,4), nrow=1)
View(theta)
x %*% theta
t(theta)
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- nrow(X);
# Randomly select 100 data points to display
sel <- sample(m);
sel <- sel[1:100];
source("displayData.R")
displayData(X[sel,]);
## Setup the parameters you will use for this part of the exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- nrow(X);
# Randomly select 100 data points to display
sel <- sample(m);
sel <- sel[1:100];
source("displayData.R")
displayData(X[sel,]);
print('Program paused. Press enter to continue.\n');
## Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all
#  Instructions
#  ------------
#
#  This file contains code that helps you get started on the
#  linear exercise. You will need to complete the following functions
#  in this exericse:
#
#     lrCostFunction.R (logistic regression cost function)
#     oneVsAll.R
#     predictOneVsAll.R
#     predict.R
#
#  For this exercise, you will not need to change any code in this file,
#  or any other files other than those mentioned above.
#
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## Setup the parameters you will use for this part of the exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- nrow(X);
# Randomly select 100 data points to display
sel <- sample(m);
sel <- sel[1:100];
source("displayData.R")
displayData(X[sel,]);
print('Program paused. Press enter to continue.\n');
install.packages("R.matlab")
## Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all
#  Instructions
#  ------------
#
#  This file contains code that helps you get started on the
#  linear exercise. You will need to complete the following functions
#  in this exericse:
#
#     lrCostFunction.R (logistic regression cost function)
#     oneVsAll.R
#     predictOneVsAll.R
#     predict.R
#
#  For this exercise, you will not need to change any code in this file,
#  or any other files other than those mentioned above.
#
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## Setup the parameters you will use for this part of the exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- nrow(X);
# Randomly select 100 data points to display
sel <- sample(m);
sel <- sel[1:100];
source("displayData.R")
displayData(X[sel,]);
print('Program paused. Press enter to continue.\n');
## ------------ Part 2: Vectorize Logistic Regression ------------
#  In this part of the exercise, you will reuse your logistic regression
#  code from the last exercise. Your task here is to make sure that your
#  regularized logistic regression implementation is vectorized. After
#  that, you will implement one-vs-all classification for the handwritten
#  digit dataset.
#
cat(sprintf('\nTraining One-vs-All Logistic Regression...\n'))
lambda <- 0.1
all_theta <- oneVsAll(X, y, num_labels, lambda)
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
## ----------------- Part 3: Predict for One-Vs-All -----------------
pred <- predictOneVsAll(all_theta, X)
cat(sprintf('\nTraining Set Accuracy: %f\n', mean(pred == y) * 100))
View(all_theta)
## Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all
#  Instructions
#  ------------
#
#  This file contains code that helps you get started on the
#  linear exercise. You will need to complete the following functions
#  in this exericse:
#
#     lrCostFunction.R (logistic regression cost function)
#     oneVsAll.R
#     predictOneVsAll.R
#     predict.R
#
#  For this exercise, you will not need to change any code in this file,
#  or any other files other than those mentioned above.
#
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## Setup the parameters you will use for this exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
hidden_layer_size <- 25;   # 25 hidden units
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- dim(X)[1]
# Randomly select 100 data points to display
sel <- sample(m)
sel <- sel[1:100]
displayData(X[sel,])
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
## ----------------- Part 2: Loading Pameters -----------------
# In this part of the exercise, we load some pre-initialized
# neural network parameters.
cat(sprintf('\nLoading Saved Neural Network Parameters ...\n'))
# Load the weights into variables Theta1 and Theta2
load('ex3weights.Rda')
list2env(data,.GlobalEnv)
rm(data)
## ------------------- Part 3: Implement Predict -------------------
#  After training the neural network, we would like to use it to predict
#  the labels. You will now implement the "predict" function to use the
#  neural network to predict the labels of the training set. This lets
#  you compute the training set accuracy.
pred <- predict(Theta1, Theta2, X)
cat(sprintf('\nTraining Set Accuracy: %f\n', mean(pred==y) * 100))
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
#  To give you an idea of the network's output, you can also run
#  through the examples one at the a time to see what it is predicting.
#  Randomly permute examples
rp <- sample(m)
for (i in 1:m){
# Display
cat(sprintf('\nDisplaying Example Image. Press Esc to End\n'))
displayData(X[rp[i], ])
pred <- predict(Theta1, Theta2, X[rp[i],])
cat(sprintf('\nNeural Network Prediction: %d (y %d) (digit %d)\n', pred ,y[rp[i]],pred%%10))
# line <- readLines(con = stdin(),1)
#cat(sprintf('Program paused. Press enter to continue.\n'))
#line <- readLines(con = stdin(),1)
Sys.sleep(2)
#press esc to quit the loop in Rstudio
}
data <- readMat("../ex3/ex3weights.mat");
list2env(data,.GlobalEnv)
rm(data)
pred <- predict(Theta1, Theta2, X)
cat(sprintf('\nTraining Set Accuracy: %f\n', mean(pred==y) * 100))
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
#  To give you an idea of the network's output, you can also run
#  through the examples one at the a time to see what it is predicting.
#  Randomly permute examples
rp <- sample(m)
for (i in 1:m){
# Display
cat(sprintf('\nDisplaying Example Image. Press Esc to End\n'))
displayData(X[rp[i], ])
pred <- predict(Theta1, Theta2, X[rp[i],])
cat(sprintf('\nNeural Network Prediction: %d (y %d) (digit %d)\n', pred ,y[rp[i]],pred%%10))
# line <- readLines(con = stdin(),1)
#cat(sprintf('Program paused. Press enter to continue.\n'))
#line <- readLines(con = stdin(),1)
Sys.sleep(2)
#press esc to quit the loop in Rstudio
}
## Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all
#  Instructions
#  ------------
#
#  This file contains code that helps you get started on the
#  linear exercise. You will need to complete the following functions
#  in this exericse:
#
#     lrCostFunction.R (logistic regression cost function)
#     oneVsAll.R
#     predictOneVsAll.R
#     predict.R
#
#  For this exercise, you will not need to change any code in this file,
#  or any other files other than those mentioned above.
#
## Initialization
if(.Platform$OS.type == "windows") {
setwd("c:/Users/omovchaniuk/Documents/GitHub/Stanford-University/week-04/machine-learning-ex3/ex3-R")
} else {
setwd("/Users/aleksey/Documents/MOOC/Coursera/ML/Stanford-University/week-04/machine-learning-ex3/ex3-R")
}
rm(list=ls())
sources <- c("displayData.R","lrCostFunction.R",
"oneVsAll.R","predict.R",
"predictOneVsAll.R","sigmoid.R")
for (i in 1:length(sources)) {
cat(paste("Loading ",sources[i],"\n"))
source(sources[i])
}
## Setup the parameters you will use for this exercise
input_layer_size  <- 400;  # 20x20 Input Images of Digits
hidden_layer_size <- 25;   # 25 hidden units
num_labels <- 10;          # 10 labels, from 1 to 10
# (note that we have mapped "0" to label 10)
## =========== Part 1: Loading and Visualizing Data =============
#  We start the exercise by first loading and visualizing the dataset.
#  You will be working with a dataset that contains handwritten digits.
#
# Load Training Data
print('Loading and Visualizing Data ...\n')
library(R.matlab)
pic <- readMat("../ex3/ex3data1.mat"); # training data stored in arrays X, y
X <- pic$X
y <- pic$y
m <- dim(X)[1]
# Randomly select 100 data points to display
sel <- sample(m)
sel <- sel[1:100]
displayData(X[sel,])
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
## ----------------- Part 2: Loading Pameters -----------------
# In this part of the exercise, we load some pre-initialized
# neural network parameters.
cat(sprintf('\nLoading Saved Neural Network Parameters ...\n'))
# Load the weights into variables Theta1 and Theta2
data <- readMat("../ex3/ex3weights.mat");
list2env(data,.GlobalEnv)
rm(data)
## ------------------- Part 3: Implement Predict -------------------
#  After training the neural network, we would like to use it to predict
#  the labels. You will now implement the "predict" function to use the
#  neural network to predict the labels of the training set. This lets
#  you compute the training set accuracy.
pred <- predict(Theta1, Theta2, X)
cat(sprintf('\nTraining Set Accuracy: %f\n', mean(pred==y) * 100))
cat(sprintf('Program paused. Press enter to continue.\n'))
line <- readLines(con = stdin(),1)
#  To give you an idea of the network's output, you can also run
#  through the examples one at the a time to see what it is predicting.
#  Randomly permute examples
rp <- sample(m)
for (i in 1:m){
# Display
cat(sprintf('\nDisplaying Example Image. Press Esc to End\n'))
displayData(X[rp[i], ])
pred <- predict(Theta1, Theta2, X[rp[i],])
cat(sprintf('\nNeural Network Prediction: %d (y %d) (digit %d)\n', pred ,y[rp[i]],pred%%10))
# line <- readLines(con = stdin(),1)
#cat(sprintf('Program paused. Press enter to continue.\n'))
#line <- readLines(con = stdin(),1)
Sys.sleep(2)
#press esc to quit the loop in Rstudio
}
